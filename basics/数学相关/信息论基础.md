# 信息论基础（以自然语言处理为背景）
## 1.概念对比表

| 概念 | 定义 | 理解 |
|-----|-----|-----|
| 1.熵H(X) | ![](../../pictures/H_x.png)| 越不确定的随机变量熵越大 |
| 2.联合熵 | ![](../../pictures/H_xy.png) | 联合熵实际上就是描述`一对随机变量`平均所需要的信息量。|
| 3.条件熵 | ![](../../pictures/H_Y_X.png) | ![](../../pictures/liansuoguize.png)不对称 |
| 4.熵率  | ![](../../pictures/H_rate.png)  |   |
| 5.相对熵，KL(距离) | ![](../../pictures/D_KL.png)  | 相对熵常被用以衡量两个随机分布的差距。（不对称） |
| 6.交叉熵 | ![](../../pictures/H_c.png)  |交叉熵的概念用以衡量估计模型与真实概率分布之间的差异。（不对称）|
| 7.稳态普遍性随机过程 | ![](../../pictures/H_s.png)  |   |
| 8.困惑度 | ![](../../pictures/H_p.png)  |   |
| 9.互信息  | ![](../../pictures/H_i.png) I(X;Y)=H(X)+H(Y)-H(X;Y) |![](../../pictures/H_i2.png)在知道了Y的值以后X的不确定性的减少量,即Y的值透露了多少关于X的信息量。（对称） |

## 附录：
- f(x)=-xlog(x)的取值：<br>
![](../../pictures/xlog_x.png)<br>
- 联合熵计算(方法1---使用连锁规则)<br>
![](../../pictures/shang.png)<br>
- 联合熵计算(方法2---使用来联合概率分布直接计算)<br>
以上：-[(1/16)*log(1/16)*4+(3/16)*log(3/16)*2+(3/8)*log(3/8)]=2.44bits
